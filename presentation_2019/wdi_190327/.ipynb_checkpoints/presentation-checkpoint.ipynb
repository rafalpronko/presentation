{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# State-of-the-art w NLP\n",
    "### ImageNet for language\n",
    "#### Rafal Pronko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rafal Pronko\n",
    "rafalpronko @ LinkedIn, Telegram, Twitter, Tungsten\n",
    "\n",
    "\n",
    "| <img src=\"czmis.png\" width=\"100\">  | <img src=\"webinterpret.png\" width=\"100\">  |  <img src=\"pm.jpg\" width=\"100\"> |\n",
    "|---|---|---|\n",
    "| <img src=\"ynd.png\" width=\"100\">  | <img src=\"cleanride.svg\" width=\"100\">  | <img src=\"cvtimeline.jpg\" width=\"100\">  |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Klasyfikacja tekstu\n",
    "\n",
    "![](text_classification.png)\n",
    "\n",
    "1. Kategoryzacja ogłoszeń na portalach (Ebay / Amazon / Allegro ...)\n",
    "2. Wykrywanie niechcianych tekstów: SPAM / mowa nienawiści ...\n",
    "3. Klasyfikacja artykułów: przypisywanie kategorii / wykrywanie nieprawdziwych informacji\n",
    "4. Klasyfikacja zawodów ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Google wybor modelu\n",
    "<img src=\"google_text_classification.png\" width=\"500\">\n",
    "\n",
    "https://developers.google.com/machine-learning/guides/text-classification/step-2-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = rus.fit_resample(df, df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"id\", \"question_text\", \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161620, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f61330815ecb292abbac</td>\n",
       "      <td>Why is there a quota in education when educati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd2f5b1bf1a9c7a04764</td>\n",
       "      <td>What is the reason that media is so under thre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edfbf901bd9cd28aedb0</td>\n",
       "      <td>Why did iron smelting in ancient times require...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fca7888ce077fb047f87</td>\n",
       "      <td>Why are there no holidays in June?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5ff781cb1a9441049c9</td>\n",
       "      <td>My dad is visiting and I am jobless now. I fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                      question_text  \\\n",
       "0  f61330815ecb292abbac  Why is there a quota in education when educati...   \n",
       "1  dd2f5b1bf1a9c7a04764  What is the reason that media is so under thre...   \n",
       "2  edfbf901bd9cd28aedb0  Why did iron smelting in ancient times require...   \n",
       "3  fca7888ce077fb047f87                 Why are there no holidays in June?   \n",
       "4  c5ff781cb1a9441049c9  My dad is visiting and I am jobless now. I fee...   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"target\"] == 0].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df[\"question_text\"] = df.question_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f61330815ecb292abbac</td>\n",
       "      <td>why is there a quota in education when educati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd2f5b1bf1a9c7a04764</td>\n",
       "      <td>what is the reason that media is so under thre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edfbf901bd9cd28aedb0</td>\n",
       "      <td>why did iron smelting in ancient times require...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fca7888ce077fb047f87</td>\n",
       "      <td>why are there no holidays in june?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5ff781cb1a9441049c9</td>\n",
       "      <td>my dad is visiting and i am jobless now. i fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                      question_text  \\\n",
       "0  f61330815ecb292abbac  why is there a quota in education when educati...   \n",
       "1  dd2f5b1bf1a9c7a04764  what is the reason that media is so under thre...   \n",
       "2  edfbf901bd9cd28aedb0  why did iron smelting in ancient times require...   \n",
       "3  fca7888ce077fb047f87                 why are there no holidays in june?   \n",
       "4  c5ff781cb1a9441049c9  my dad is visiting and i am jobless now. i fee...   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import SeparableConv1D, Convolution1D, Bidirectional, GRU\n",
    "from tensorflow.python.keras.layers import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.preprocessing import text\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"question_text\"], df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "TOP_K = 20001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 60\n",
    "MAX_VECTOR_EMD = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sequence_vectorize(train_texts, val_texts):\n",
    "    \"\"\"Vectorizes texts as sequence vectors.\n",
    "\n",
    "    1 text = 1 sequence vector with fixed length.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val, word_index: vectorized training and validation\n",
    "            texts and word index dictionary.\n",
    "    \"\"\"\n",
    "    # Create vocabulary with training texts.\n",
    "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Vectorize training and validation texts.\n",
    "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "    # Get max sequence length.\n",
    "    max_length = len(max(x_train, key=len))\n",
    "    if max_length > MAX_SEQUENCE_LENGTH:\n",
    "        max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "    # Fix sequence length to max value. Sequences shorter than the length are\n",
    "    # padded in the beginning and sequences longer are truncated\n",
    "    # at the beginning.\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
    "    return x_train, x_val, tokenizer.word_index, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train_seq, X_test_seq, idxs, tok = sequence_vectorize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def sepcnn_model(blocks,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 embedding_dim,\n",
    "                 dropout_rate,\n",
    "                 pool_size,\n",
    "                 input_shape,\n",
    "                 num_classes,\n",
    "                 num_features,\n",
    "                 use_pretrained_embedding=False,\n",
    "                 is_embedding_trainable=False,\n",
    "                 embedding_matrix=None):\n",
    "    \"\"\"Creates an instance of a separable CNN model.\n",
    "\n",
    "    # Arguments\n",
    "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
    "        filters: int, output dimension of the layers.\n",
    "        kernel_size: int, length of the convolution window.\n",
    "        embedding_dim: int, dimension of the embedding vectors.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "        num_features: int, number of words (embedding input dimension).\n",
    "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
    "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
    "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
    "\n",
    "    # Returns\n",
    "        A sepCNN model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
    "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
    "    if use_pretrained_embedding:\n",
    "        model.add(Embedding(input_dim=num_features,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=input_shape[0],\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=is_embedding_trainable))\n",
    "    else:\n",
    "        model.add(Embedding(input_dim=num_features,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=input_shape[0]))\n",
    "    \n",
    "    for _ in range(blocks-1):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(SeparableConv1D(filters=filters,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  activation='relu',\n",
    "                                  bias_initializer='random_uniform',\n",
    "                                  depthwise_initializer='random_uniform',\n",
    "                                  padding='same'))\n",
    "        model.add(SeparableConv1D(filters=filters,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  activation='relu',\n",
    "                                  bias_initializer='random_uniform',\n",
    "                                  depthwise_initializer='random_uniform',\n",
    "                                  padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "    model.add(SeparableConv1D(filters=filters * 2,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='relu',\n",
    "                              bias_initializer='random_uniform',\n",
    "                              depthwise_initializer='random_uniform',\n",
    "                              padding='same'))\n",
    "    model.add(SeparableConv1D(filters=filters * 2,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='relu',\n",
    "                              bias_initializer='random_uniform',\n",
    "                              depthwise_initializer='random_uniform',\n",
    "                              padding='same'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = sepcnn_model(blocks=4,\n",
    "                     filters=32,\n",
    "                     kernel_size=5,\n",
    "                     embedding_dim=MAX_VECTOR_EMD,\n",
    "                     dropout_rate=0.2,\n",
    "                     pool_size=3,\n",
    "                     input_shape=(MAX_SEQUENCE_LENGTH,),\n",
    "                     num_classes=2,\n",
    "                     num_features=TOP_K,\n",
    "                     use_pretrained_embedding=False,\n",
    "                     is_embedding_trainable=True,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 60, 200)           4000200   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 60, 200)           0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_33 (Separab (None, 60, 32)            7432      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_34 (Separab (None, 60, 32)            1216      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_35 (Separab (None, 20, 32)            1216      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_36 (Separab (None, 20, 32)            1216      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_37 (Separab (None, 6, 32)             1216      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_38 (Separab (None, 6, 32)             1216      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_39 (Separab (None, 2, 64)             2272      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_40 (Separab (None, 2, 64)             4480      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,021,521\n",
      "Trainable params: 4,021,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121215 samples, validate on 40405 samples\n",
      "Epoch 1/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 51s 417us/step - loss: 1.4153 - acc: 0.5402 - val_loss: 0.5786 - val_acc: 0.7203\n",
      "\n",
      "Epoch 2/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 50s 412us/step - loss: 0.4248 - acc: 0.8153 - val_loss: 0.3304 - val_acc: 0.8728\n",
      "\n",
      "Epoch 3/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 49s 404us/step - loss: 0.3170 - acc: 0.8760 - val_loss: 0.2934 - val_acc: 0.8846\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1577a6080>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, y_train, validation_data=(X_test_seq, y_test), epochs=3, batch_size=512,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bidirectional LSTM\n",
    "<img src=\"bidirectional.png\" width=\"800\">\n",
    "\n",
    "\n",
    "https://hackernoon.com/what-kagglers-are-using-for-text-classification-c695b58b5709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def gru_model(num_features, embedding_dim, input_shape, num_classes):\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(input_dim=num_features,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=input_shape[0]))\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(64, return_sequences=False)))\n",
    "    model.add(Dense(op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_gru = gru_model(embedding_dim=MAX_VECTOR_EMD,\n",
    "                        input_shape=(MAX_SEQUENCE_LENGTH,),\n",
    "                        num_features=TOP_K,\n",
    "                       num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_gru.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 60, 200)           4000200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         252672    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               123264    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,376,265\n",
      "Trainable params: 4,376,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121215 samples, validate on 40405 samples\n",
      "Epoch 1/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 415s 3ms/step - loss: 0.4478 - acc: 0.7754 - val_loss: 0.3064 - val_acc: 0.8776\n",
      "\n",
      "Epoch 2/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 409s 3ms/step - loss: 0.2660 - acc: 0.8969 - val_loss: 0.2763 - val_acc: 0.8927\n",
      "\n",
      "Epoch 3/3\n",
      "121215/121215 [==============================]121215/121215 [==============================] - 419s 3ms/step - loss: 0.2349 - acc: 0.9110 - val_loss: 0.2746 - val_acc: 0.8932\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x167905f28>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru.fit(X_train_seq, y_train, validation_data=(X_test_seq, y_test), epochs=3, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention\n",
    "<img src=\"attention.png\" width=\"800\">\n",
    "\n",
    "\n",
    "https://hackernoon.com/what-kagglers-are-using-for-text-classification-c695b58b5709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(TOP_K,\n",
    "        MAX_VECTOR_EMD,\n",
    "        input_length=60,\n",
    "        trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "lstm_layer = LSTM(128, dropout=0.2, recurrent_dropout=0.2,return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "comment_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences= embedding_layer(comment_input)\n",
    "x = lstm_layer(embedded_sequences)\n",
    "x = Dropout(0.2)(x)\n",
    "merged = Attention(MAX_SEQUENCE_LENGTH)(x)\n",
    "merged = Dense(128, activation=\"relu\")(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_att = Model(inputs=[comment_input], outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 60, 200)           4000200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 128)           168448    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 128)               188       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,185,477\n",
      "Trainable params: 4,185,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_att.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_att.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121215 samples, validate on 40405 samples\n",
      "Epoch 1/3\n",
      "121215/121215 [==============================] - 184s 2ms/step - loss: 0.3789 - acc: 0.8304 - val_loss: 0.2826 - val_acc: 0.8887\n",
      "Epoch 2/3\n",
      "121215/121215 [==============================] - 195s 2ms/step - loss: 0.2560 - acc: 0.9029 - val_loss: 0.2742 - val_acc: 0.8927\n",
      "Epoch 3/3\n",
      "121215/121215 [==============================] - 186s 2ms/step - loss: 0.2308 - acc: 0.9151 - val_loss: 0.2772 - val_acc: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173bbb748>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_att.fit(X_train_seq, y_train, validation_data=(X_test_seq, y_test), epochs=3, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Podsumowanie wynikow\n",
    "\n",
    "CNN - 0.8846\n",
    "\n",
    "GRU - 0.8932\n",
    "\n",
    "ATT - 0.8920\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Embedding\n",
    "\n",
    "1. BoW\n",
    "2. Word2Vec (CBOW i skip-gram model) - lokalny kontekst \n",
    "3. GloVe - stara sie wziac pod uwage kontekst globalny\n",
    "4. FastText - zbudowany na Word2Vec jednak stara sie znalezc konteksty sub-slow (uczony jak Word2Vec + ngramy w slowie - na koncu jest usredniany)\n",
    "5. ELMo (Embedding from Language Model) - pozwala na rozpoznanie sensu slowa w danym kontekscie\n",
    "6. BERT - Podobny do ELMo ale... uczony inaczej\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sentence = Sentence('Stick to the marked trails.')\n",
    "sentence2 = Sentence('I intend to stick to my promise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Stick to the marked trails.\" - 5 Tokens\n",
      "Sentence: \"I intend to stick to my promise.\" - 7 Tokens\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Stick\n",
      "tensor([-0.6643,  0.1528, -0.2895, -0.4068, -0.4737,  0.2733, -0.2304,  0.0374,\n",
      "        -0.2698, -0.2610, -0.3525,  0.3428,  0.4750,  0.6637, -0.5283,  0.3865,\n",
      "        -0.0985,  0.2492, -0.2734, -0.5586,  0.0603,  0.5039, -0.5368,  0.0660,\n",
      "         0.3239,  0.5892, -0.6452, -0.1834,  0.0057,  0.2798, -0.0065,  1.2641,\n",
      "         0.0600,  0.1529,  0.1453, -0.1880,  0.2369, -0.2504,  0.6144, -0.9344,\n",
      "        -0.0688, -0.5705,  0.4045, -0.4111, -1.3672, -0.3098, -0.3376, -0.0909,\n",
      "        -0.6633, -0.6661, -0.0061,  0.0937, -0.4293,  1.4003,  0.0140, -1.6013,\n",
      "         0.2068,  0.3280,  1.0206,  0.0566,  0.5846,  0.4398, -0.8114,  0.4312,\n",
      "        -0.0174, -0.0137,  0.0159,  0.4674, -0.6148, -0.5592, -0.0948, -0.1868,\n",
      "         0.3186,  0.0247, -0.0717, -0.2578, -0.3763,  0.2470,  0.4026,  0.2124,\n",
      "         0.0916,  0.0474, -0.6611, -0.3974, -0.6042, -0.0321,  0.1920,  0.6081,\n",
      "         0.0280,  0.2510, -0.5960,  0.2214, -0.5980, -0.5555, -0.5342, -1.0906,\n",
      "        -0.4165, -0.2219,  0.8241,  0.2481])\n",
      "Token: 2 to\n",
      "tensor([-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01])\n",
      "Token: 3 the\n",
      "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
      "Token: 4 marked\n",
      "tensor([-4.3279e-01, -8.8524e-06, -4.0274e-02,  2.6440e-01,  4.3178e-01,\n",
      "        -3.7478e-02, -4.4058e-02,  1.7926e-01, -4.3359e-01, -9.7395e-02,\n",
      "        -3.2387e-01, -2.4604e-01,  7.5851e-01, -2.9089e-01,  3.2053e-01,\n",
      "         3.2779e-01,  1.1621e-01, -4.2644e-01, -1.5931e-02, -4.2233e-01,\n",
      "         6.4027e-01, -2.8250e-01, -1.7631e-01,  4.3474e-01,  4.4826e-01,\n",
      "        -4.6483e-01, -2.5283e-02,  3.4554e-01,  3.0022e-01, -8.0838e-01,\n",
      "         1.7470e-01, -9.4023e-02,  2.0470e-01,  2.4464e-01,  2.5772e-01,\n",
      "        -3.8456e-01,  4.6041e-01, -3.4487e-01, -6.6325e-01,  3.2508e-01,\n",
      "         1.1001e-01, -5.0070e-01,  7.3845e-01,  4.2609e-01,  1.2405e-01,\n",
      "        -1.9726e-01,  8.8046e-01,  3.2579e-01, -8.1886e-03, -6.7306e-01,\n",
      "         6.1517e-01, -6.1256e-01,  1.3934e-01,  8.8168e-01, -2.4491e-01,\n",
      "        -2.1214e+00, -3.3455e-01,  1.3600e-01,  1.1424e+00,  2.1591e-01,\n",
      "        -7.7616e-01,  7.7624e-01, -7.5073e-02, -3.5422e-01,  3.7271e-01,\n",
      "        -2.3682e-01,  9.7167e-02, -6.4449e-01,  1.6375e-01, -2.5944e-01,\n",
      "        -4.7573e-02,  3.5139e-01, -3.9886e-01,  7.0267e-02,  5.0854e-01,\n",
      "         3.0586e-01,  1.4556e-01,  4.0783e-01, -6.9672e-01, -1.7087e-01,\n",
      "         1.2992e-01, -9.9193e-02, -3.6836e-02, -8.9344e-03, -9.2521e-01,\n",
      "        -5.9910e-01, -5.4184e-02, -8.1336e-01,  2.0107e-02, -1.7827e-01,\n",
      "        -5.7281e-01,  2.2079e-01, -6.1397e-01,  7.2423e-01, -4.0049e-01,\n",
      "        -7.2394e-01, -7.4207e-02, -2.3125e-01, -1.3754e-01, -2.3578e-02])\n",
      "Token: 5 trails.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "glove_embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 I\n",
      "tensor([-0.0465,  0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,\n",
      "         0.1468, -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100,\n",
      "        -0.2811,  0.6051, -1.0654,  0.5248,  0.0642,  1.0358, -0.4078, -0.3801,\n",
      "         0.3080,  0.5996, -0.2699, -0.7603,  0.9422, -0.4692, -0.1828,  0.9065,\n",
      "         0.7967,  0.2482,  0.2571,  0.6232, -0.4477,  0.6536,  0.7690, -0.5123,\n",
      "        -0.4433, -0.2187,  0.3837, -1.1483, -0.9440, -0.1506,  0.3001, -0.5781,\n",
      "         0.2017, -1.6591, -0.0792,  0.0264,  0.2205,  0.9971, -0.5754, -2.7266,\n",
      "         0.3145,  0.7052,  1.4381,  0.9913,  0.1398,  1.3474, -1.1753,  0.0040,\n",
      "         1.0298,  0.0646,  0.9089,  0.8287, -0.4700, -0.1058,  0.5916, -0.4221,\n",
      "         0.5733, -0.5411,  0.1077,  0.3978, -0.0487,  0.0646, -0.6144, -0.2860,\n",
      "         0.5067, -0.4976, -0.8157,  0.1641, -1.9630, -0.2669, -0.3759, -0.9585,\n",
      "        -0.8584, -0.7158, -0.3234, -0.4312,  0.4139,  0.2837, -0.7093,  0.1500,\n",
      "        -0.2154, -0.3762, -0.0325,  0.8062])\n",
      "Token: 2 intend\n",
      "tensor([-0.1246, -0.2116, -0.3664,  0.1640, -0.4381, -0.2911, -0.4910,  0.4126,\n",
      "         0.5432,  0.2491, -0.0374,  0.3858, -0.0158, -0.4033, -1.0672, -0.2856,\n",
      "         0.1409,  0.8178, -0.8741,  0.1390,  0.0194, -0.1217, -0.2034, -0.3431,\n",
      "        -0.9343, -0.0295,  0.2871, -0.3137,  0.5697, -0.2593, -0.0950,  0.6857,\n",
      "        -0.0026, -0.1709,  0.2354,  0.2923,  0.3106, -0.5531,  0.4486,  0.1032,\n",
      "        -0.3422,  0.3558,  0.3047, -0.3508, -0.6970, -0.3570,  0.2903, -0.3844,\n",
      "        -0.4926, -1.2540,  0.3250,  0.2166,  0.2008,  0.3898,  0.1233, -0.8240,\n",
      "         0.3254, -0.5160,  0.8232,  0.0276, -0.3666,  0.2133, -0.6444, -0.2240,\n",
      "         0.8616,  0.5305,  0.2349,  1.0555, -0.7932, -0.5688,  0.5092, -0.7478,\n",
      "        -0.1207, -0.9039, -0.4159,  0.1713, -0.2430,  0.1455, -0.2364, -0.1367,\n",
      "         0.0096, -0.3313, -0.4233,  0.1348, -0.8074, -0.4391,  0.4620,  0.4687,\n",
      "        -0.0170,  0.0981, -0.1339, -0.3380,  0.1707, -0.7680, -0.2432, -0.0178,\n",
      "        -0.1456, -0.0930,  0.2458,  0.3652])\n",
      "Token: 3 to\n",
      "tensor([-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01])\n",
      "Token: 4 stick\n",
      "tensor([-0.6643,  0.1528, -0.2895, -0.4068, -0.4737,  0.2733, -0.2304,  0.0374,\n",
      "        -0.2698, -0.2610, -0.3525,  0.3428,  0.4750,  0.6637, -0.5283,  0.3865,\n",
      "        -0.0985,  0.2492, -0.2734, -0.5586,  0.0603,  0.5039, -0.5368,  0.0660,\n",
      "         0.3239,  0.5892, -0.6452, -0.1834,  0.0057,  0.2798, -0.0065,  1.2641,\n",
      "         0.0600,  0.1529,  0.1453, -0.1880,  0.2369, -0.2504,  0.6144, -0.9344,\n",
      "        -0.0688, -0.5705,  0.4045, -0.4111, -1.3672, -0.3098, -0.3376, -0.0909,\n",
      "        -0.6633, -0.6661, -0.0061,  0.0937, -0.4293,  1.4003,  0.0140, -1.6013,\n",
      "         0.2068,  0.3280,  1.0206,  0.0566,  0.5846,  0.4398, -0.8114,  0.4312,\n",
      "        -0.0174, -0.0137,  0.0159,  0.4674, -0.6148, -0.5592, -0.0948, -0.1868,\n",
      "         0.3186,  0.0247, -0.0717, -0.2578, -0.3763,  0.2470,  0.4026,  0.2124,\n",
      "         0.0916,  0.0474, -0.6611, -0.3974, -0.6042, -0.0321,  0.1920,  0.6081,\n",
      "         0.0280,  0.2510, -0.5960,  0.2214, -0.5980, -0.5555, -0.5342, -1.0906,\n",
      "        -0.4165, -0.2219,  0.8241,  0.2481])\n",
      "Token: 5 to\n",
      "tensor([-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01])\n",
      "Token: 6 my\n",
      "tensor([ 0.0803, -0.1086,  0.7207, -0.4514, -0.7496,  0.6378, -0.2571,  0.4161,\n",
      "        -0.0545,  0.3556,  0.3586,  0.5400,  0.4912,  0.2571, -0.2147, -0.4284,\n",
      "        -0.4232,  0.3872, -0.3569,  0.4012, -0.1985,  0.4345, -0.3648,  0.0717,\n",
      "         0.5332,  0.8456, -0.6754, -1.2527,  0.8376, -0.1593,  0.3780,  0.9454,\n",
      "         0.8307,  0.1943, -0.5845,  0.5828, -0.6256,  0.4904,  0.4327, -0.5425,\n",
      "         0.1045, -0.1626,  0.9900, -0.7422, -0.5978,  0.1019, -0.3357, -0.3909,\n",
      "         0.1513, -1.3533, -0.1126,  0.1435,  0.0381,  1.1167, -0.2308, -2.6394,\n",
      "         0.6685,  0.4845,  1.8796,  0.0803,  0.7373,  1.8058, -0.5193,  0.0041,\n",
      "         0.7699,  0.3688,  0.8114,  0.1694, -0.1192, -0.2650,  0.2269,  0.7694,\n",
      "         0.8520, -0.9777,  0.2318,  0.8814, -0.2709, -0.3991, -0.5719,  0.0756,\n",
      "         0.1809,  0.5904, -0.1343, -0.1206, -1.8157, -0.3550, -0.3172, -0.2704,\n",
      "        -0.6723, -0.0410, -0.4433,  0.3565,  1.0247,  0.4969, -0.5170, -0.4928,\n",
      "        -0.3340, -0.3484,  0.3147,  1.0087])\n",
      "Token: 7 promise.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "glove_embedding.embed(sentence2)\n",
    "for token in sentence2:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s1_stick = 0\n",
    "for token in sentence:\n",
    "    if (token.text == 'stick') or ((token.text == 'Stick')):\n",
    "        s1_stick = token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s2_stick = 0\n",
    "for token in sentence2:\n",
    "    if (token.text == 'stick') or ((token.text == 'Stick')):\n",
    "        s2_stick = token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_stick == s2_stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import BertEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "embedding = BertEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('Stick to the marked trails.')\n",
    "sentence2 = Sentence('I intend to stick to my promise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Stick\n",
      "tensor([ 0.3480,  0.2575,  0.0822,  ...,  0.5876, -0.8315, -0.3655])\n"
     ]
    }
   ],
   "source": [
    "embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    if (token.text == 'stick') or ((token.text == 'Stick')):\n",
    "        print(token)\n",
    "        print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 stick\n",
      "tensor([ 0.5259,  0.4349,  0.5928,  ...,  0.9525, -0.0109, -0.3207])\n"
     ]
    }
   ],
   "source": [
    "embedding.embed(sentence2)\n",
    "for token in sentence2:\n",
    "    if (token.text == 'stick') or ((token.text == 'Stick')):\n",
    "        print(token)\n",
    "        print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```__label__<class_1> <text>\n",
    "__label__<class_2> <text>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"target\"] = \"__label__\"+df[\"target\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df[\"drop\"] = df.question_text.apply(lambda x: 1 if len(x.split()) > 60 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161620, 3)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>question_text</th>\n",
       "      <th>drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>why is there a quota in education when educati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>what is the reason that media is so under thre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>why did iron smelting in ancient times require...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>why are there no holidays in june?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>my dad is visiting and i am jobless now. i fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                      question_text  drop\n",
       "0  __label__0  why is there a quota in education when educati...     0\n",
       "1  __label__0  what is the reason that media is so under thre...     0\n",
       "2  __label__0  why did iron smelting in ancient times require...     0\n",
       "3  __label__0                 why are there no holidays in june?     0\n",
       "4  __label__0  my dad is visiting and i am jobless now. i fee...     0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"drop\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = df[[\"target\", \"question_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f\n",
    "df.iloc[0:int(len(df)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "df.iloc[int(len(df)*0.8):int(len(df)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "df.iloc[int(len(df)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentPoolEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-27 12:58:37,309 Reading data from .\n",
      "2019-03-27 12:58:37,311 Train: train.csv\n",
      "2019-03-27 12:58:37,313 Dev: dev.csv\n",
      "2019-03-27 12:58:37,314 Test: test.csv\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv',\n",
    "                                                       dev_file='dev.csv', train_file='train.csv')\n",
    "\n",
    "word_embeddings = [embedding]\n",
    "\n",
    "document_embeddings = DocumentPoolEmbeddings(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-27 12:59:17,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-27 12:59:17,660 Evaluation method: MICRO_F1_SCORE\n",
      "2019-03-27 12:59:17,665 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-27 12:59:21,698 epoch 1 - iter 0/4041 - loss 0.02329264\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(document_embeddings,\n",
    "                            label_dictionary=corpus.make_label_dictionary(),\n",
    "                            multi_label=False)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "trainer.train('', max_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Podsumowanie\n",
    "CNN - 0.8846\n",
    "\n",
    "GRU - 0.8932\n",
    "\n",
    "ATT - 0.8920\n",
    "\n",
    "Flair - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](bert_banch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ULMFiT Universal Language Model Fine-tuning for Text Classification\n",
    "\n",
    "![](ulm.png)\n",
    "\n",
    "http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q&A\n",
    "\n",
    "\n",
    "rafalpronko @ LinkedIn, Telegram, Twitter, Tungsten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
